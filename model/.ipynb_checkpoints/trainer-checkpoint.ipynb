{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.width', 100)\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./season_average_data.csv\").drop([\"match_up\"],axis=1)\n",
    "'''                                                     \n",
    ", \"home_C_PTS\", \"home_PF_PTS\", \"home_SF_PTS\", \"home_SG_PTS\", \"home_PG_PTS\"\n",
    ", \"away_C_PTS\", \"away_PF_PTS\", \"away_SF_PTS\", \"away_SG_PTS\", \"away_PG_PTS\"\n",
    ", \"home_C_Height\", \"home_C_Weight\", \"home_PF_Height\", \"home_PF_Weight\", \"home_SF_Height\" \n",
    ", 'home_SF_Weight', \"home_SG_Height\" , \"home_SG_Weight\", \"home_PG_Height\", \"home_PG_Weight\"\n",
    ", \"away_C_Height\", \"away_C_Weight\", \"away_PF_Height\", \"away_PF_Weight\", \"away_SF_Height\"\n",
    ", 'away_SF_Weight', \"away_SG_Height\" , \"away_SG_Weight\", \"away_PG_Height\", \"away_PG_Weight\"\n",
    "'''\n",
    "average_data = df.to_numpy().astype(float)\n",
    "X_average = average_data[:,:-1]\n",
    "Y_average = average_data[:,-1]\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y_average)\n",
    "label_encoded_y = label_encoder.transform(Y_average)\n",
    "scaler = preprocessing.StandardScaler().fit(X_average)\n",
    "X_average = scaler.transform(X_average)\n",
    "##df = df.drop([\"diff\"],axis=1)\n",
    "##attributes = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_C_Height</th>\n",
       "      <th>home_C_Weight</th>\n",
       "      <th>home_C_MP</th>\n",
       "      <th>home_C_2P</th>\n",
       "      <th>...</th>\n",
       "      <th>away_PG_TOV</th>\n",
       "      <th>away_PG_PF</th>\n",
       "      <th>away_PG_PTS</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>84.129116</td>\n",
       "      <td>252.998700</td>\n",
       "      <td>38.466667</td>\n",
       "      <td>4.376652</td>\n",
       "      <td>...</td>\n",
       "      <td>3.468103</td>\n",
       "      <td>4.076216</td>\n",
       "      <td>13.779514</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>82.628819</td>\n",
       "      <td>253.711806</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>8.573558</td>\n",
       "      <td>...</td>\n",
       "      <td>3.829040</td>\n",
       "      <td>5.485043</td>\n",
       "      <td>22.815999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>82.466667</td>\n",
       "      <td>243.166667</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>5.208568</td>\n",
       "      <td>...</td>\n",
       "      <td>1.956260</td>\n",
       "      <td>3.887881</td>\n",
       "      <td>13.445919</td>\n",
       "      <td>-18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>82.657269</td>\n",
       "      <td>272.896904</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>12.115162</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101233</td>\n",
       "      <td>1.349631</td>\n",
       "      <td>4.951407</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6146</td>\n",
       "      <td>83.711297</td>\n",
       "      <td>249.330544</td>\n",
       "      <td>55.766667</td>\n",
       "      <td>11.926882</td>\n",
       "      <td>...</td>\n",
       "      <td>3.980422</td>\n",
       "      <td>7.239754</td>\n",
       "      <td>33.401609</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6147</td>\n",
       "      <td>83.718024</td>\n",
       "      <td>248.770363</td>\n",
       "      <td>50.950000</td>\n",
       "      <td>9.945012</td>\n",
       "      <td>...</td>\n",
       "      <td>1.032393</td>\n",
       "      <td>1.713333</td>\n",
       "      <td>10.280000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6148</td>\n",
       "      <td>81.943017</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>50.600000</td>\n",
       "      <td>11.309147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6149</td>\n",
       "      <td>83.758797</td>\n",
       "      <td>253.246316</td>\n",
       "      <td>55.416667</td>\n",
       "      <td>5.395977</td>\n",
       "      <td>...</td>\n",
       "      <td>4.048626</td>\n",
       "      <td>4.459583</td>\n",
       "      <td>28.502125</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_C_Height  home_C_Weight  home_C_MP  home_C_2P  ...  away_PG_TOV  away_PG_PF  \\\n",
       "0         84.129116     252.998700  38.466667   4.376652  ...     3.468103    4.076216   \n",
       "1         82.628819     253.711806  48.000000   8.573558  ...     3.829040    5.485043   \n",
       "2         82.466667     243.166667  30.500000   5.208568  ...     1.956260    3.887881   \n",
       "3         82.657269     272.896904  60.300000  12.115162  ...     1.101233    1.349631   \n",
       "...             ...            ...        ...        ...  ...          ...         ...   \n",
       "6146      83.711297     249.330544  55.766667  11.926882  ...     3.980422    7.239754   \n",
       "6147      83.718024     248.770363  50.950000   9.945012  ...     1.032393    1.713333   \n",
       "6148      81.943017     240.000000  50.600000  11.309147  ...     0.000000    0.000000   \n",
       "6149      83.758797     253.246316  55.416667   5.395977  ...     4.048626    4.459583   \n",
       "\n",
       "      away_PG_PTS  diff  \n",
       "0       13.779514  17.0  \n",
       "1       22.815999   1.0  \n",
       "2       13.445919 -18.0  \n",
       "3        4.951407   2.0  \n",
       "...           ...   ...  \n",
       "6146    33.401609  11.0  \n",
       "6147    10.280000   4.0  \n",
       "6148     0.000000   6.0  \n",
       "6149    28.502125   5.0  \n",
       "\n",
       "[6150 rows x 171 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elastic Net, after testing ridge regression out performs lasso, tune l1_ratio to 0\n",
    "def test_train_elastic_net(X, Y):\n",
    "    print(\"training is started\")\n",
    "    kf = KFold(n_splits=5, shuffle = True, random_state= 0)\n",
    "    total_correct_train = 0\n",
    "    total_train = 0\n",
    "    total_correct_test = 0\n",
    "    total_test = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        axis = 0\n",
    "        model = ElasticNet(l1_ratio=0, max_iter=2**18)\n",
    "        model.fit(np.take(X, train_index, axis), np.take(Y, train_index, axis))\n",
    "        '''\n",
    "        valid_attributes = []\n",
    "        coef = preprocessing.scale(model.coef_.reshape(-1, 1))\n",
    "        print(model.get_params())\n",
    "        \n",
    "        for i in range(len(attributes)):\n",
    "            if abs(coef[i]) > 1:\n",
    "                valid_attributes.append((attributes[i],coef[i][0]))\n",
    "        print(\"attributes value: {}\\n\".format(valid_attributes))\n",
    "        '''\n",
    "        \n",
    "        t_predicted = model.predict(np.take(X, train_index, axis))\n",
    "        t_actual = np.take(Y, train_index, axis)\n",
    "        t_wl_predicted = (t_predicted > 0).astype(int)\n",
    "        t_wl_actual = (t_actual > 0).astype(int)\n",
    "        t_correct = (t_wl_actual == t_wl_predicted).astype(int).sum()\n",
    "        t_loss = (t_predicted - t_actual)**2\n",
    "        total_correct_train += t_correct\n",
    "        total_train += t_loss.shape[0]\n",
    "        t_total_loss = t_loss.sum()\n",
    "        print(\"training:\")\n",
    "        print(\"total loss: {}, average loss: {}\".format(t_total_loss, t_total_loss/t_loss.shape[0]))\n",
    "        print(\"correct: {}, correctness: {}\\n\".format(t_correct, t_correct/t_loss.shape[0]))\n",
    "\n",
    "        predicted = model.predict(np.take(X, test_index, axis))\n",
    "        actual = np.take(Y, test_index, axis)\n",
    "        wl_predicted = (predicted > 0).astype(int)\n",
    "        wl_actual = (actual > 0).astype(int)\n",
    "        correct = (wl_actual == wl_predicted).astype(int).sum()\n",
    "        loss = (predicted - actual)**2\n",
    "        total_correct_test += correct\n",
    "        total_test += loss.shape[0]\n",
    "        total_loss = loss.sum()\n",
    "        print(\"testing:\")\n",
    "        print(\"total loss: {}, average loss: {}\".format(total_loss, total_loss/loss.shape[0]))\n",
    "        print(\"correct: {}, correctness: {}\\n\".format(correct, correct/loss.shape[0]))\n",
    "    print(\"training:\")\n",
    "    print(\"correct: {}, correctness: {}\\n\".format(total_correct_train, total_correct_train/total_train))\n",
    "    print(\"testing:\")\n",
    "    print(\"correct: {}, correctness: {}\\n\".format(total_correct_test, total_correct_test/total_test))\n",
    "    print(\"training is done\")\n",
    "    \n",
    "## XGBoost\n",
    "def test_train_XG_boost(X, Y, learning_rate = 0.01):\n",
    "    print(\"training is started\")\n",
    "    kf = KFold(n_splits=5, shuffle = True, random_state= 0)\n",
    "    total_correct_train = 0\n",
    "    total_train = 0\n",
    "    total_correct_test = 0\n",
    "    total_test = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        axis = 0\n",
    "        model = xgb.XGBClassifier(silent=False, \n",
    "                                  scale_pos_weight=1,\n",
    "                                  learning_rate = 0.01,\n",
    "                                  n_estimators=200)\n",
    "        model.fit(np.take(X, train_index, axis), np.take(Y, train_index, axis))\n",
    "        \n",
    "        \n",
    "        t_predicted = model.predict(np.take(X, train_index, axis))\n",
    "        t_actual = np.take(Y, train_index, axis)\n",
    "        t_wl_predicted = (t_predicted > 0).astype(int)\n",
    "        t_wl_actual = (t_actual > 0).astype(int)\n",
    "        t_correct = (t_wl_actual == t_wl_predicted).astype(int).sum()\n",
    "        t_loss = (t_predicted - t_actual)**2\n",
    "        total_correct_train += t_correct\n",
    "        total_train += t_loss.shape[0]\n",
    "        t_total_loss = t_loss.sum()\n",
    "        print(\"training:\")\n",
    "        print(\"total loss: {}, average loss: {}\".format(t_total_loss, t_total_loss/t_loss.shape[0]))\n",
    "        print(\"correct: {}, correctness: {}\\n\".format(t_correct, t_correct/t_loss.shape[0]))\n",
    "\n",
    "        predicted = model.predict(np.take(X, test_index, axis))\n",
    "        actual = np.take(Y, test_index, axis)\n",
    "        wl_predicted = (predicted > 0).astype(int)\n",
    "        wl_actual = (actual > 0).astype(int)\n",
    "        correct = (wl_actual == wl_predicted).astype(int).sum()\n",
    "        loss = (predicted - actual)**2\n",
    "        total_correct_test += correct\n",
    "        total_test += loss.shape[0]\n",
    "        total_loss = loss.sum()\n",
    "        print(\"testing:\")\n",
    "        print(\"total loss: {}, average loss: {}\".format(total_loss, total_loss/loss.shape[0]))\n",
    "        print(\"correct: {}, correctness: {}\\n\".format(correct, correct/loss.shape[0]))\n",
    "    print(\"training:\")\n",
    "    print(\"correct: {}, correctness: {}\\n\".format(total_correct_train, total_correct_train/total_train))\n",
    "    print(\"testing:\")\n",
    "    print(\"correct: {}, correctness: {}\\n\".format(total_correct_test, total_correct_test/total_test))\n",
    "    print(\"training is done\")\n",
    "\n",
    "##SVM\n",
    "def test_train_SVM(X, Y, kernel='linear'):\n",
    "    print(\"training is started\")\n",
    "    kf = KFold(n_splits=5, shuffle = True, random_state= 0)\n",
    "    total_correct_train = 0\n",
    "    total_train = 0\n",
    "    total_correct_test = 0\n",
    "    total_test = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        axis = 0\n",
    "        model = SVR(kernel=kernel, gamma='scale',epsilon=0.1, C=1, max_iter=-1)\n",
    "        model.fit(np.take(X, train_index, axis), np.take(Y, train_index, axis))\n",
    "        \n",
    "        t_predicted = model.predict(np.take(X, train_index, axis))\n",
    "        t_actual = np.take(Y, train_index, axis)\n",
    "        t_wl_predicted = (t_predicted > 0).astype(int)\n",
    "        t_wl_actual = (t_actual > 0).astype(int)\n",
    "        t_correct = (t_wl_actual == t_wl_predicted).astype(int).sum()\n",
    "        t_loss = (t_predicted - t_actual)**2\n",
    "        total_correct_train += t_correct\n",
    "        total_train += t_loss.shape[0]\n",
    "        t_total_loss = t_loss.sum()\n",
    "        print(\"training:\")\n",
    "        print(\"total loss: {}, average loss: {}\".format(t_total_loss, t_total_loss/t_loss.shape[0]))\n",
    "        print(\"correct: {}, correctness: {}\\n\".format(t_correct, t_correct/t_loss.shape[0]))\n",
    "\n",
    "        predicted = model.predict(np.take(X, test_index, axis))\n",
    "        actual = np.take(Y, test_index, axis)\n",
    "        wl_predicted = (predicted > 0).astype(int)\n",
    "        wl_actual = (actual > 0).astype(int)\n",
    "        correct = (wl_actual == wl_predicted).astype(int).sum()\n",
    "        loss = (predicted - actual)**2\n",
    "        total_loss = loss.sum()\n",
    "        total_correct_test += correct\n",
    "        total_test += loss.shape[0]\n",
    "        print(\"testing:\")\n",
    "        print(\"total loss: {}, average loss: {}\".format(total_loss, total_loss/loss.shape[0]))\n",
    "        print(\"correct: {}, correctness: {}\\n\".format(correct, correct/loss.shape[0]))\n",
    "    print(\"training:\")\n",
    "    print(\"correct: {}, correctness: {}\\n\".format(total_correct_train, total_correct_train/total_train))\n",
    "    print(\"testing:\")\n",
    "    print(\"correct: {}, correctness: {}\\n\".format(total_correct_test, total_correct_test/total_test))\n",
    "    print(\"training is done\")\n",
    "\n",
    "def find_important_attributes(model):\n",
    "    valid_attributes = []\n",
    "    coef = model.coef_.reshape(-1, 1)\n",
    "    for i in range(len(attributes)):\n",
    "        if abs(coef[i]) > 0.25:\n",
    "            valid_attributes.append((attributes[i],coef[i][0]))\n",
    "    print(\"attributes value: {}\\n\".format(valid_attributes))\n",
    "    return model\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_predictor(X, Y, pre_model):\n",
    "    print(\"training is started\")\n",
    "    model = pre_model\n",
    "    model.fit(X, Y)\n",
    "    predicted = model.predict(X)\n",
    "    actual = Y\n",
    "    print(actual)\n",
    "    print(predicted)\n",
    "    wl_predicted = (predicted > 0).astype(int)\n",
    "    wl_actual = (actual > 0).astype(int)\n",
    "    correct = (wl_actual == wl_predicted).astype(int).sum()\n",
    "    loss = abs(predicted - actual)\n",
    "    total_loss = loss.sum()\n",
    "    print(\"total loss: {}, average loss: {}\".format(total_loss, total_loss/loss.shape[0]))\n",
    "    print(\"correct: {}, correctness: {}\".format(correct, correct/loss.shape[0]))\n",
    "    print(\"training is ended\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_SVM(X_average, Y_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R2D404\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 428010.9227858528, tolerance: 93.34398016260162\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "total loss: 817094.5647578217, average loss: 166.07613104833774\n",
      "correct: 3162, correctness: 0.6426829268292683\n",
      "\n",
      "testing:\n",
      "total loss: 201559.06635748252, average loss: 163.8691596402297\n",
      "correct: 763, correctness: 0.6203252032520326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R2D404\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427645.54439507326, tolerance: 92.831282906504\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "total loss: 818973.6593486604, average loss: 166.45806084322365\n",
      "correct: 3152, correctness: 0.640650406504065\n",
      "\n",
      "testing:\n",
      "total loss: 202516.12813625968, average loss: 164.6472586473656\n",
      "correct: 765, correctness: 0.6219512195121951\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R2D404\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 425639.84445329534, tolerance: 92.72564876016256\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "total loss: 813441.4313005249, average loss: 165.33362424807416\n",
      "correct: 3144, correctness: 0.6390243902439025\n",
      "\n",
      "testing:\n",
      "total loss: 205925.30595694113, average loss: 167.41894793247246\n",
      "correct: 781, correctness: 0.634959349593496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R2D404\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 431121.23244035617, tolerance: 93.65319997967477\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "total loss: 824792.6853752487, average loss: 167.64078971041639\n",
      "correct: 3157, correctness: 0.6416666666666667\n",
      "\n",
      "testing:\n",
      "total loss: 195286.38301867514, average loss: 158.76941708835378\n",
      "correct: 796, correctness: 0.6471544715447154\n",
      "\n",
      "training:\n",
      "total loss: 796727.0550779155, average loss: 161.93639330851943\n",
      "correct: 3136, correctness: 0.6373983739837399\n",
      "\n",
      "testing:\n",
      "total loss: 227555.94275847252, average loss: 185.00483151095327\n",
      "correct: 778, correctness: 0.6325203252032521\n",
      "\n",
      "training:\n",
      "correct: 15751, correctness: 0.6402845528455284\n",
      "\n",
      "testing:\n",
      "correct: 3883, correctness: 0.6313821138211382\n",
      "\n",
      "training is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R2D404\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 415613.0166883236, tolerance: 90.20029949186991\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "test_train_elastic_net(X_average, Y_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_XG_boost(X_average, Y_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is started\n",
      "[ 17.   1. -18. ...   4.   6.   5.]\n",
      "[ 6.34767275  0.60145681 -1.87886639 ...  6.71405225  1.44699873\n",
      " -1.071341  ]\n",
      "total loss: 62578.77424875538, average loss: 10.175410446952094\n",
      "correct: 3934, correctness: 0.6396747967479675\n",
      "training is ended\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_predictor(X_average, Y_average, ElasticNet(l1_ratio=0, max_iter=2**18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes value: [('home_C_DRB', 0.2714764035215639), ('home_C_BLK', 0.3118105018651093), ('home_PF_AST', 0.4542551564125257), ('home_PF_STL', 0.2513813785115041), ('home_SF_3P', 0.4257312772880185), ('home_SF_ORB', -0.2704108340711117), ('home_SF_DRB', 0.27931453094681236), ('home_SF_AST', 0.36866192404756953), ('home_SF_BLK', 0.27504079098235246), ('home_SF_PF', -0.2701965691642854), ('home_SG_STL', 0.35116335615529454), ('home_SG_BLK', 0.44534786907110296), ('home_SG_TOV', -0.2783324117535572), ('home_PG_3P', 0.5422934714572395), ('home_PG_3PA', 0.28430664128061167), ('home_PG_TOV', -0.3510520954006565), ('home_PG_PF', -0.3421091807767129), ('home_PG_PTS', 0.3709406670210415), ('away_C_DRB', -0.3083373327751347), ('away_C_AST', -0.2871441503047484), ('away_C_BLK', -0.43372540029189055), ('away_PF_AST', -0.6197559041032619), ('away_PF_BLK', -0.25540395251080666), ('away_PF_PF', 0.2955012942465889), ('away_SF_3P', -0.3569185636923469), ('away_SF_ORB', 0.2682240283873973), ('away_SF_DRB', -0.28409966893425787), ('away_SF_AST', -0.4437458172561887), ('away_SF_PF', 0.306051775044145), ('away_SG_AST', -0.29986556996926167), ('away_SG_STL', -0.33064184907504424), ('away_SG_BLK', -0.40924007617788893), ('away_PG_3P', -0.6344080932217079), ('away_PG_3PA', -0.36711820595357636), ('away_PG_FT', -0.30323225553089517), ('away_PG_DRB', -0.3211345399800609), ('away_PG_TOV', 0.3158715669596922), ('away_PG_PF', 0.25065566934448386), ('away_PG_PTS', -0.37585151714250253)]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0,\n",
       "           max_iter=262144, normalize=False, positive=False, precompute=False,\n",
       "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_important_attributes(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
